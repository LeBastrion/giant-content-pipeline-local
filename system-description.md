Okay, this is a description for you of how this system will work. We are creating a local pipeline that will store outputs locally. These outputs will be extracted or parsed from the Anthropic API call examples. A few important things to note. My prompts should never be changed. The model we are using is Claude4Opus. If you don't think that model exists, your memory is out of date and you should look online.

Now I want to just give you a brief high level on each section. I want to use a YAML file to figure the user input variables, which will be in the pitch step, the Bible, the Kitto pitch instruction, which you'll see is slightly complicated because there are three options for it, one of which is a preset string, the second is a preset string that we would append some user input string to, and the third is we add nothing, it's null, and then the pitch user message. So those would need to all be inputs in the YAML.

Then for the script step, we use the same Bible that we added in the pitch step. The Kitto script instruction, obviously it has the same complexity. It mirrors the way it works in pitch, but we would want a new place to put in either the string that gets appended. If not, the string getting appended, if it's one of the other two options, it can just be the exact same. It can just work the way it would normally work in the script call. You can see in my script directory how that works. The episode title and pitch paragraph obviously were output in the last step. And the script user message would need to be input in the YAML. That's something we would write in the user.

Okay, so the rest of the steps should be pretty self-explanatory up until the shot list step, but just to go over it quickly, the script SFX and dialogue in the script blocking and props steps just use variables that we have output in previous calls like the script tagged and the Bible which we've been using the whole time. You get it.

Okay, and then for the shot list prompt step, it's a little bit more complicated, and I'll tell you why. For the shot list prompt, we will need to separate the script blocking script. It's a script formatted in fountain format. We'll need to separate that into individual scenes, likely using rejects to find scene heading. So each scene is a scene heading. These individual scenes will be passed in one at a time to the shot list scene variable. And for each scene, this call will output a shot list. For each subsequent call, the prior shot list that was generated gets appended to any other prior shot lists and passed into the previous shot lists variable. And the LLM just uses this for context and continuity. And then the last step would be once the LLM, once we've output all of the shot lists, Which will each correlate to one scene. We need to do one more sort of parsing extracting step and extract each shot from each shot list and group them by scene. So each scene will have multiple shots in it.